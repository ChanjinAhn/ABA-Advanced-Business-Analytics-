{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the online retail dataset\n",
    "data = pd.read_csv('./data/amazon.csv')\n",
    "df = data[:100].copy()\n",
    "df.dropna(subset=['rating_count'], inplace=True)\n",
    "\n",
    "df['sub_category'] = df['category'].astype(str).str.split('|').str[-1]\n",
    "df['main_category'] = df['category'].astype(str).str.split('|').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'product_name', 'category', 'discounted_price',\n",
       "       'actual_price', 'discount_percentage', 'rating', 'rating_count',\n",
       "       'about_product', 'user_id', 'user_name', 'review_id', 'review_title',\n",
       "       'review_content', 'img_link', 'product_link', 'sub_category',\n",
       "       'main_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['product_name'] = df1['product_name'].str.lower() \n",
    "df1 = df1.drop_duplicates(subset=['product_name'])    # Remove duplicates based on 'product_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 18)\n",
      "(100, 18)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Product Name & Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wayona nylon braided usb to lightning fast charging and data sync cable compatible for iphone 13, 12,11, x, 8, 7, 6, 5, ipad air, pro, mini (3 ft pack of 1, grey)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['product_name'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     High Compatibility : Compatible With iPhone 12...\n",
       "1     Compatible with all Type C enabled devices, be...\n",
       "2     【 Fast Charger& Data Sync】-With built-in safet...\n",
       "3     The boAt Deuce USB 300 2 in 1 cable is compati...\n",
       "4     [CHARGE & SYNC FUNCTION]- This cable comes wit...\n",
       "                            ...                        \n",
       "95    Supports 150Mbps Wireless data transmission ra...\n",
       "96    Compatible with MI Smart TV 4A 32 inch LED TV ...\n",
       "97    The cable comes with 3 Different pins allowing...\n",
       "98    Fastest USB 3.0 and Gigabit solution ensure hi...\n",
       "99    【Power Delivery Fast Charging】: Charge your iP...\n",
       "Name: about_product, Length: 100, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['about_product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1[['product_id','product_name', 'about_product','main_category','sub_category', 'actual_price','discount_percentage','rating','rating_count' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>about_product</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>actual_price</th>\n",
       "      <th>discount_percentage</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B07JW9H4J1</td>\n",
       "      <td>wayona nylon braided usb to lightning fast cha...</td>\n",
       "      <td>High Compatibility : Compatible With iPhone 12...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>USBCables</td>\n",
       "      <td>₹1,099</td>\n",
       "      <td>64%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>24,269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B098NS6PVG</td>\n",
       "      <td>ambrane unbreakable 60w / 3a fast charging 1.5...</td>\n",
       "      <td>Compatible with all Type C enabled devices, be...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>USBCables</td>\n",
       "      <td>₹349</td>\n",
       "      <td>43%</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43,994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B096MSW6CT</td>\n",
       "      <td>sounce fast phone charging cable &amp; data sync u...</td>\n",
       "      <td>【 Fast Charger&amp; Data Sync】-With built-in safet...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>USBCables</td>\n",
       "      <td>₹1,899</td>\n",
       "      <td>90%</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7,928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08HDJ86NZ</td>\n",
       "      <td>boat deuce usb 300 2 in 1 type-c &amp; micro usb s...</td>\n",
       "      <td>The boAt Deuce USB 300 2 in 1 cable is compati...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>USBCables</td>\n",
       "      <td>₹699</td>\n",
       "      <td>53%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>94,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B08CF3B7N1</td>\n",
       "      <td>portronics konnect l 1.2m fast charging 3a 8 p...</td>\n",
       "      <td>[CHARGE &amp; SYNC FUNCTION]- This cable comes wit...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>USBCables</td>\n",
       "      <td>₹399</td>\n",
       "      <td>61%</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16,905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                       product_name  \\\n",
       "0  B07JW9H4J1  wayona nylon braided usb to lightning fast cha...   \n",
       "1  B098NS6PVG  ambrane unbreakable 60w / 3a fast charging 1.5...   \n",
       "2  B096MSW6CT  sounce fast phone charging cable & data sync u...   \n",
       "3  B08HDJ86NZ  boat deuce usb 300 2 in 1 type-c & micro usb s...   \n",
       "4  B08CF3B7N1  portronics konnect l 1.2m fast charging 3a 8 p...   \n",
       "\n",
       "                                       about_product          main_category  \\\n",
       "0  High Compatibility : Compatible With iPhone 12...  Computers&Accessories   \n",
       "1  Compatible with all Type C enabled devices, be...  Computers&Accessories   \n",
       "2  【 Fast Charger& Data Sync】-With built-in safet...  Computers&Accessories   \n",
       "3  The boAt Deuce USB 300 2 in 1 cable is compati...  Computers&Accessories   \n",
       "4  [CHARGE & SYNC FUNCTION]- This cable comes wit...  Computers&Accessories   \n",
       "\n",
       "  sub_category actual_price discount_percentage rating rating_count  \n",
       "0    USBCables       ₹1,099                 64%    4.2       24,269  \n",
       "1    USBCables         ₹349                 43%    4.0       43,994  \n",
       "2    USBCables       ₹1,899                 90%    3.9        7,928  \n",
       "3    USBCables         ₹699                 53%    4.2       94,363  \n",
       "4    USBCables         ₹399                 61%    4.2       16,905  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('data/amazon_rag.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Document\n",
    "- Document Loader\tData Type\n",
    "- CSVLoader\tCSV files\n",
    "- DirectoryLoader\tAll files in a given directory\n",
    "- Unstructured\tMany file types (see https://docs.unstructured.io/platform/supported-file-types)\n",
    "- JSONLoader\tJSON files\n",
    "- BSHTMLLoader\tHTML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.document_loaders.csv_loader import CSVLoader\n",
    "# from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "# from langchain_community.document_loaders import NotionDirectoryLoader, NotionDBLoader\n",
    "\n",
    "# loader = DirectoryLoader(\"../\", glob=\"**/*.md\", loader_cls=TextLoader)\n",
    "# docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema.document import Document\n",
    "\n",
    "\n",
    "# This will expose your Langchain api token as an environment variable\n",
    "load_dotenv()\n",
    "\n",
    "# def read_csv(file_path: str, source_column: str = \"about_product\") -> List[Document]:\n",
    "def read_csv(file_path: str, source_column: str = \"product_name\") -> List[Document]:\n",
    "    \"\"\"Reads a CSV file and returns a list of Documents.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file to read.\n",
    "        source_column (str, optional): The name of the column in the CSV file that contains the text data. Defaults to \"Description\".\n",
    "\n",
    "    Returns:\n",
    "        List[Document]: A list of Documents, where each Document contains the text data from the corresponding row in the CSV file.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the CSV file does not exist.\n",
    "        IOError: If there is an error reading the CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
    "\n",
    "    loader = CSVLoader(file_path=file_path, source_column=source_column)\n",
    "    data = loader.load()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Embedding Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Token\n",
    "- reference: https://huggingface.co/docs/hub/security-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the token\n",
    "os.environ[\"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\"] = '' #본인의 Hugging Face token 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#reference: https://python.langchain.com/docs/integrations/providers/huggingface/#huggingfaceembeddings\n",
    "# model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
    "model_name = 'jhgan/ko-sroberta-nli'\n",
    "\n",
    "# Function to load embeddings model\n",
    "def load_embeddings_model(model_name: str) -> HuggingFaceEmbeddings:\n",
    "    \"\"\"Loads a Hugging Face Transformer model and returns an Embeddings object.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the Hugging Face Transformer model to load.\n",
    "\n",
    "    Returns:\n",
    "        HuggingFaceEmbeddings: An Embeddings object that can be used to encode text into embeddings.\n",
    "    \"\"\"\n",
    "    embedding_function = HuggingFaceEmbeddings(\n",
    "        model_name=model_name,\n",
    "        huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
    "        model_kwargs={'device':'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings':True}\n",
    "    )\n",
    "    return embedding_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f2c31701fc4b6697da2c79c91034c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acj00\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acj00\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730f07fa9b69476c9051f10c23b78f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7ddf3092d84ec0a29deb8a5b244ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacd40b3fc774f0fb25c2624b880547d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bfb7fb6f5e423ab2b5c75231ca9076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdead06753940c1a5d74b15f78a601b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da663ad515c4df087d17afb1ecc3e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f73eea656a4419c80dd78852059c12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f71dfbdfc834c29a3c5e4cc69c785b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfd7de09f6d4da6a564539cc9700ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4006b8a5041c4733b4be3b42d321151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.89517488e-02 -3.98619249e-02 -2.15627961e-02  9.90846660e-03\n",
      "  -3.81040238e-02  1.26843844e-02  4.34945486e-02  7.18339905e-02\n",
      "   9.74856503e-03 -6.98698079e-03  6.35281429e-02 -3.03226467e-02\n",
      "   1.38394646e-02  2.58058943e-02 -1.13624346e-03 -1.45636220e-02\n",
      "   4.16402668e-02  3.62282805e-02 -2.68008839e-02  2.51206737e-02\n",
      "  -2.49786302e-02 -4.53322427e-03 -2.66672336e-02  4.10072273e-03\n",
      "  -5.20480089e-02 -9.93037038e-03 -5.20652793e-02  8.99204239e-03\n",
      "  -3.83005217e-02 -4.40584458e-02 -4.20440501e-03  7.04797134e-02\n",
      "   5.13389474e-03 -7.16154054e-02  1.69753173e-06 -6.04771404e-03\n",
      "  -1.10763488e-02  1.75133739e-02 -2.22998373e-02  4.09549549e-02\n",
      "   3.37901674e-02  5.66503368e-02 -7.11493790e-02  4.09766398e-02\n",
      "  -5.90610830e-03 -3.29703279e-02 -4.01169434e-02  3.69054787e-02\n",
      "   1.04445955e-02  7.07238093e-02  1.90010853e-03 -1.20581510e-02\n",
      "   4.28838059e-02 -4.50334251e-02  1.06468126e-01 -5.94848348e-03\n",
      "  -1.17971823e-02  2.58937515e-02  3.90455052e-02 -1.23679964e-02\n",
      "   1.53814731e-02 -3.13428491e-02 -5.07326052e-03 -1.23161972e-02\n",
      "  -2.45000212e-03 -2.87188962e-02  5.03502414e-02 -5.12134880e-02\n",
      "   3.74327004e-02  8.31524935e-03  1.11046486e-01  8.44687410e-03\n",
      "   1.98060577e-03  6.40625656e-02 -2.02479046e-02  5.64443320e-02\n",
      "  -1.23114511e-02 -3.62594128e-02  2.81707123e-02 -2.55367253e-02\n",
      "   2.34403946e-02 -3.74669395e-02 -3.50409225e-02 -2.67592501e-02\n",
      "  -2.38361303e-02 -3.88771854e-03 -3.29223312e-02 -3.01778372e-02\n",
      "  -9.55944241e-04  1.80032253e-02  2.90016015e-03 -3.47949117e-02\n",
      "  -2.58908365e-02  1.97209010e-05  7.75027275e-02 -1.56728141e-02\n",
      "  -5.64411208e-02 -1.23693526e-01  7.44356588e-02  1.45308943e-02\n",
      "   4.15601507e-02 -2.48618387e-02 -2.24028956e-02  5.85677102e-02\n",
      "  -3.24664228e-02  4.10865694e-02  7.88500085e-02  1.36464182e-02\n",
      "   9.00347624e-03  9.83375907e-02  8.42196774e-03  4.84131044e-03\n",
      "  -3.81185152e-02 -2.56237178e-03  4.12396938e-02 -2.41733938e-02\n",
      "   2.94954628e-02  4.98188799e-03  7.00795185e-03  7.85086825e-02\n",
      "   1.84720568e-02 -2.16636509e-02 -2.59122029e-02  9.71266720e-03\n",
      "  -2.57666633e-02 -5.96665591e-02  9.27380566e-03 -2.45250762e-02\n",
      "   2.65204459e-02 -4.33670059e-02  2.08227187e-02  2.81026065e-02\n",
      "   3.25606577e-02  2.96974555e-02 -1.26540149e-02  2.77971625e-02\n",
      "   3.90072018e-02 -3.65074575e-02  2.72418209e-03 -1.34109659e-02\n",
      "   5.86156659e-02  1.97788496e-02  2.23103035e-02  1.51104210e-02\n",
      "  -2.56598331e-02  3.08283139e-02  2.67824065e-03 -1.54350018e-02\n",
      "   1.43316230e-02  2.74256356e-02 -9.56855156e-03  2.70560235e-02\n",
      "   2.76362291e-03  7.31118629e-03  2.58504902e-03 -2.57125776e-02\n",
      "   1.89351980e-02 -2.76865046e-02 -1.39433136e-02 -1.68813951e-02\n",
      "   1.59710906e-02 -1.07734436e-02  3.08209885e-04 -2.50462200e-02\n",
      "   1.42203728e-02  3.99305150e-02  1.17468229e-02  4.33355616e-03\n",
      "  -1.85634680e-02 -1.73030067e-02 -5.58661558e-02 -9.96198598e-03\n",
      "  -1.50362235e-02  6.30918816e-02 -1.35290269e-02  8.17803890e-02\n",
      "   5.36863543e-02 -4.18102965e-02 -5.74638881e-02  5.48502356e-02\n",
      "  -6.37755170e-03 -3.35376114e-02 -2.60766614e-02  9.46401060e-03\n",
      "  -3.80509533e-02  3.63594368e-02 -5.16790524e-02 -5.55973686e-02\n",
      "   7.56068621e-03 -8.20393674e-03 -6.73056841e-02  1.15537765e-02\n",
      "   4.41139843e-03 -1.21971508e-02  4.29788930e-03  3.84116136e-02\n",
      "  -3.53282504e-02 -1.76244392e-03 -7.74322683e-03 -1.36757866e-02\n",
      "   2.96334773e-02  1.39268348e-02  8.10792148e-02  6.56443313e-02\n",
      "   1.20347720e-02 -2.24933270e-02  4.18024361e-02 -5.04193641e-02\n",
      "  -6.25815184e-04  2.93729044e-02  1.32781431e-01  7.50964461e-03\n",
      "  -5.46133146e-02 -1.33336373e-02 -5.74462116e-03 -3.26234661e-02\n",
      "   6.98460441e-04  1.46948295e-02 -4.53371508e-03  1.41089456e-02\n",
      "   1.83794880e-03 -6.38915300e-02 -2.92422995e-02  4.14627306e-02\n",
      "   5.94098307e-03 -1.18546158e-01 -1.69115551e-02  2.45524291e-02\n",
      "   4.04210463e-02 -2.03592181e-02 -4.52010520e-02 -3.84764746e-03\n",
      "   2.46012565e-02  8.12466517e-02  1.28162932e-02  1.48726851e-02\n",
      "   2.84779370e-02  3.18273995e-03 -2.47095209e-02 -8.80538151e-02\n",
      "  -1.06115974e-02  3.66704389e-02  2.95828958e-03  4.00643088e-02\n",
      "  -4.54834625e-02 -3.46410424e-02 -2.14755489e-03 -3.68058234e-02\n",
      "   1.48498388e-02 -2.04166733e-02 -1.46225654e-02 -2.65132566e-03\n",
      "  -4.49197069e-02 -1.32715493e-03  1.11650359e-02  1.82113536e-02\n",
      "   1.18334480e-02 -1.83855905e-03 -1.89428087e-02 -1.08595984e-02\n",
      "   7.09208939e-03 -5.43679018e-03 -3.48272594e-03 -2.94997226e-02\n",
      "   4.90274765e-02  2.12204363e-02 -3.01434733e-02 -5.84686659e-02\n",
      "  -9.74646211e-03 -4.91970405e-03  2.47147027e-02  4.92718909e-03\n",
      "  -2.03451253e-02 -1.81205869e-02  1.60938371e-02 -5.28443605e-02\n",
      "  -4.53450456e-02 -1.14913341e-02 -2.57848185e-02  1.63059402e-02\n",
      "  -3.03553734e-02  3.91156338e-02 -2.67774314e-02 -5.28594200e-03\n",
      "   5.91661362e-03  4.16531451e-02  5.18280128e-03 -1.77771971e-02\n",
      "  -4.49651852e-02  6.21292442e-02  4.24922332e-02  1.38942609e-02\n",
      "   5.75621538e-02  2.19774526e-03 -7.05103809e-03 -1.96154807e-02\n",
      "  -4.41104062e-02  4.90744300e-02  1.30787659e-02  5.76159917e-02\n",
      "  -1.97687428e-02  1.92947444e-02 -2.16712169e-02 -1.99713577e-02\n",
      "   2.56270338e-02  7.86260068e-02  6.82736859e-02 -8.11096504e-02\n",
      "  -2.43091650e-04 -2.60209339e-03  2.16325484e-02  1.86136961e-02\n",
      "   5.40621066e-03  8.60013533e-03 -5.48213162e-02 -1.60730502e-03\n",
      "   1.95033047e-02  1.11619104e-02 -3.47883180e-02 -2.96559278e-02\n",
      "   9.43301059e-03 -4.73012403e-03 -9.56353359e-03 -2.88972221e-02\n",
      "   1.82347354e-02 -5.37331104e-02  4.99218255e-02  1.51745994e-02\n",
      "  -1.22185163e-02 -3.93678173e-02 -1.78290196e-02 -1.25932125e-02\n",
      "  -3.52298245e-02  1.58811919e-02  2.72073429e-02  3.22236121e-02\n",
      "  -2.98027955e-02 -1.32830543e-02 -1.73229240e-02 -7.74441520e-03\n",
      "  -2.96526309e-02 -3.96901183e-03 -2.51602585e-04 -1.69640575e-02\n",
      "   6.05710335e-02  2.59260852e-02 -1.62438639e-02  4.88078184e-02\n",
      "  -7.82101378e-02  7.66160432e-03  2.45039910e-02  6.21896908e-02\n",
      "  -2.42370162e-02 -2.75783837e-02 -1.67850573e-02  1.15696201e-02\n",
      "  -1.14248414e-03 -3.21983695e-02  1.68347750e-02 -6.42628819e-02\n",
      "  -4.50123511e-02 -1.88893843e-02  3.37315211e-03  8.32737684e-02\n",
      "  -8.74169730e-03 -1.28535982e-02 -2.21941564e-02 -1.36377625e-02\n",
      "  -1.14491256e-02  5.81929600e-03 -4.62681726e-02  1.06320661e-02\n",
      "   1.29690189e-02  3.82187441e-02 -2.29122629e-03  1.50756873e-02\n",
      "   1.91104971e-03 -3.76792774e-02 -7.24994764e-02 -8.41162819e-03\n",
      "   3.69696692e-02 -1.75586455e-02  6.88061714e-02  2.14540083e-02\n",
      "   1.55879222e-02  5.68537973e-02  2.92110108e-02  8.10101535e-03\n",
      "   2.57022455e-02  1.77271180e-02  1.23445317e-02 -6.84504164e-03\n",
      "  -2.80874949e-02  1.40132410e-02  1.39519004e-02  2.48028710e-02\n",
      "   3.25996019e-02 -1.25237228e-02 -4.36118292e-03 -9.91583429e-03\n",
      "   2.84513738e-03 -1.67978760e-02 -3.01434286e-02  1.61706191e-02\n",
      "   5.34095094e-02 -2.83818077e-02  1.78549252e-02  1.05774906e-02\n",
      "  -2.16342323e-02 -1.61008239e-02  1.10833710e-02 -6.76256865e-02\n",
      "   5.92874251e-02 -1.05303107e-02  1.22864107e-02 -3.91062116e-03\n",
      "   8.29421449e-03  3.52652594e-02 -1.22320801e-02 -2.07327139e-02\n",
      "  -3.11598741e-02  1.09008560e-02 -4.53912740e-04 -3.68727595e-02\n",
      "  -3.12885270e-02 -2.62433868e-02  8.71406216e-03 -6.76977169e-03\n",
      "  -8.91410513e-04  1.31757921e-02 -1.72173455e-02 -4.08580229e-02\n",
      "  -4.40644734e-02  4.71085720e-02 -7.33435899e-02  1.01020839e-02\n",
      "  -6.43117502e-02 -3.11587639e-02  7.40809962e-02 -6.89630806e-02\n",
      "  -2.38872711e-02  1.51002174e-02  9.81070623e-02  7.63778080e-05\n",
      "  -6.58845305e-02 -1.87850986e-02 -4.28492092e-02 -1.51737947e-02\n",
      "   3.27682644e-02  3.47692743e-02  1.94546785e-02 -3.52351069e-02\n",
      "  -4.27905694e-02 -2.76387874e-02  5.25933541e-02 -1.36987343e-02\n",
      "  -2.30158307e-02  2.23553530e-03 -2.41393503e-02  1.96558554e-02\n",
      "  -5.01368418e-02  3.98957580e-02 -6.70992583e-02 -1.96422562e-02\n",
      "  -6.66542305e-03 -3.07304715e-03 -5.59397973e-02 -4.59426567e-02\n",
      "  -7.01805670e-03 -9.67997778e-03 -9.00472030e-02 -4.29662783e-03\n",
      "  -2.67626960e-02  1.31586883e-02 -8.69640242e-03 -2.39961985e-02\n",
      "  -7.95711353e-02  4.90419790e-02 -2.61667538e-02 -2.39589196e-02\n",
      "   4.10787761e-02 -3.35832238e-02  1.80230066e-02 -1.42742936e-02\n",
      "  -1.13908295e-02  5.50044142e-02 -3.37664830e-03 -4.52326424e-03\n",
      "   4.88888584e-02 -3.01691052e-02 -2.47159451e-02 -1.32854860e-02\n",
      "   4.58147656e-03  5.25676161e-02 -4.14648615e-02  3.56987976e-02\n",
      "   3.17288376e-02  2.21275464e-02  1.10920481e-02 -2.60619167e-02\n",
      "   5.48389927e-03 -1.87523030e-02 -3.40702198e-02 -5.24508357e-02\n",
      "  -7.46851265e-02  1.92564651e-02  1.09306108e-02  6.08953871e-02\n",
      "  -2.81504099e-03  3.41596454e-02  1.25679579e-02 -6.94108382e-03\n",
      "   1.95761863e-02  1.60676278e-02 -3.51016484e-02  2.14354321e-02\n",
      "  -7.84991980e-02 -3.78198959e-02 -3.21763419e-02 -3.55202630e-02\n",
      "   2.02446822e-02  5.56273117e-05  1.08797811e-02 -2.72172578e-02\n",
      "  -1.76897366e-02 -9.67134954e-04  4.21083681e-02  1.88538004e-02\n",
      "  -3.06383409e-02  2.85667069e-02  4.04225886e-02 -4.68258224e-02\n",
      "  -8.43898803e-02  5.13432249e-02 -5.90534918e-02  5.02689555e-02\n",
      "   6.80840462e-02  2.34913044e-02  7.94641860e-03 -5.95372282e-02\n",
      "   4.05580401e-02 -4.48616743e-02  8.32668394e-02  1.57494005e-02\n",
      "   3.06371041e-03  1.06408605e-02 -1.10924281e-02  4.24710512e-02\n",
      "  -1.63912661e-02 -3.56704034e-02  2.93838307e-02  4.60404716e-02\n",
      "   2.78490665e-03  2.06446014e-02  2.51023266e-02 -5.93341500e-33\n",
      "  -2.40009539e-02 -1.82696581e-02 -1.15751792e-02  3.25872526e-02\n",
      "   6.24997616e-02  1.66833010e-02 -1.84607543e-02 -6.27345825e-03\n",
      "  -1.15952892e-02 -1.14933085e-02 -2.40798257e-02 -9.88784432e-03\n",
      "   4.71380837e-02 -2.34081643e-03 -1.83017477e-02  2.93425117e-02\n",
      "   3.68524082e-02 -2.52381451e-02 -3.09845973e-02 -3.88257392e-02\n",
      "  -6.14290982e-02 -4.16413136e-02  5.25314510e-02  9.17158276e-03\n",
      "   7.77427573e-03 -5.37155243e-03 -1.29830614e-02 -6.30903766e-02\n",
      "  -3.46298739e-02  6.05907757e-03  1.77322011e-02 -4.16764170e-02\n",
      "   1.88157801e-03  1.87844131e-02  6.28543273e-03  9.27202553e-02\n",
      "  -5.16202971e-02 -4.39469926e-02  4.33706725e-03  2.90268771e-02\n",
      "  -3.31403837e-02  1.15648620e-02 -8.39530863e-03 -5.50343208e-02\n",
      "   1.48198176e-02 -2.74847783e-02 -1.01731056e-02  2.09493414e-02\n",
      "  -4.53028642e-02 -6.49845577e-04 -6.50299415e-02  1.86906960e-02\n",
      "  -3.19593609e-03  7.67844096e-02  2.09663212e-02  5.79188503e-02\n",
      "   1.84116501e-03 -1.12847060e-01 -3.33609506e-02 -1.34434560e-02\n",
      "   5.36525026e-02  7.48745119e-03  2.73195654e-02 -4.49071229e-02\n",
      "   2.94993958e-03  1.16592152e-02 -5.77611066e-02  1.11958452e-01\n",
      "   3.17497402e-02 -4.26889807e-02  7.71101266e-02  1.54688461e-02\n",
      "   2.21320558e-02  6.47064596e-02 -4.31337068e-03  8.15070642e-04\n",
      "   3.64596471e-02  5.52556552e-02  4.50738147e-02  2.72720791e-02\n",
      "   2.79280897e-02 -3.78543325e-02 -4.70189713e-02 -1.92826912e-02\n",
      "  -3.57822552e-02 -3.49272341e-02 -2.10345518e-02 -3.68296839e-02\n",
      "   3.23470645e-02  6.68179651e-04  3.45066041e-02  3.36459316e-02\n",
      "  -1.40163088e-02 -3.83431790e-03 -6.10291399e-03  4.31840532e-02\n",
      "  -7.63413962e-03  2.08677240e-02 -4.69006449e-02 -6.62512407e-02\n",
      "  -2.28751246e-02 -2.23192461e-02  4.66140211e-02  1.69540066e-02\n",
      "   3.45936194e-02 -1.02270264e-02  1.15313455e-02 -2.23165173e-02\n",
      "  -8.70613158e-02 -9.94122028e-03  1.93632338e-02  1.98197942e-02\n",
      "   4.79802676e-02 -2.61088982e-02  1.80123688e-03  2.78752167e-02\n",
      "   4.24294099e-02 -5.18925721e-03 -1.98234078e-02 -9.29940194e-02\n",
      "  -7.74643617e-03  2.03233510e-02  1.03626493e-02 -4.71892627e-03\n",
      "   1.78525075e-02 -9.55087226e-03  1.08678034e-02  2.01142449e-02\n",
      "   4.19505201e-02  1.70065183e-02  2.55750269e-02  4.11611125e-02\n",
      "   2.19379402e-07  4.66837510e-02  5.98651394e-02 -1.79038860e-03\n",
      "   4.45071459e-02  2.05496661e-02 -6.27486855e-02 -2.74117868e-02\n",
      "   3.06502730e-02  1.21085346e-02  2.63819192e-02  2.34872792e-02\n",
      "  -5.43454885e-02  4.07596417e-02  6.82877377e-02 -4.87759486e-02\n",
      "   6.71142712e-03  3.39813787e-03 -2.61358880e-02 -2.69508013e-03\n",
      "  -2.03517508e-02  3.20764296e-02 -7.28126988e-03  4.39593941e-03\n",
      "  -1.35354791e-02 -1.22104981e-03 -1.71895009e-02 -6.44381437e-03\n",
      "  -2.75772214e-02 -1.88159719e-02 -2.26969104e-02 -1.64652197e-03\n",
      "  -1.55673055e-02  3.06490213e-02  8.34562927e-02 -5.15088886e-02\n",
      "  -6.21994119e-03  1.52098453e-02  7.05551058e-02  8.78885575e-03\n",
      "   5.23011982e-02  2.09231116e-02 -7.69612491e-02 -7.99653679e-03\n",
      "  -9.19552613e-03  3.45574766e-02  6.59144893e-02  6.45219907e-02\n",
      "  -2.90987603e-02 -6.82507828e-02 -5.45135401e-02  2.64128409e-02\n",
      "  -8.66518170e-03  2.50032637e-02  5.19749476e-03  1.14129419e-02\n",
      "  -6.14573881e-02 -8.84679612e-03  4.97258268e-02  3.54320928e-02\n",
      "   3.75494994e-02 -4.15783077e-02  1.16358940e-02  1.91227738e-02\n",
      "   1.91565696e-02  2.01898664e-02 -2.31142007e-02  6.88359665e-04\n",
      "   1.76729675e-34 -3.41377198e-03 -2.94105466e-02 -3.32652288e-03\n",
      "  -2.27811392e-02 -7.76679954e-03 -1.75740514e-02  1.01725869e-01\n",
      "   3.78334746e-02 -1.15501881e-02 -5.87819107e-02 -1.15691759e-02]]\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings_model(model_name: str) -> SentenceTransformer:\n",
    "    \"\"\"Loads a SentenceTransformer model and returns it.\"\"\"\n",
    "    # SentenceTransformer를 사용하여 모델을 로드\n",
    "    model = SentenceTransformer(model_name)\n",
    "    return model\n",
    "\n",
    "# Load the embeddings\n",
    "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "embeddings = load_embeddings_model(model_name)\n",
    "\n",
    "# Test embedding a query\n",
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.encode([text])  # SentenceTransformer에서 사용하는 방식\n",
    "print(query_result[:3])  # 출력되는 벡터의 처음 세 개의 값만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_documents(data: List[Document], embedding_function: HuggingFaceEmbeddings) -> Chroma:\n",
    "    \"\"\"Vectorizes a list of Documents using a Hugging Face Transformer model.\n",
    "\n",
    "    Args:\n",
    "        data (List[Document]): A list of Documents to vectorize.\n",
    "        embedding_function (HuggingFaceEmbeddings): An Embeddings object that can be used to encode text into embeddings.\n",
    "\n",
    "    Returns:\n",
    "        Chroma: A Chroma object that contains the vectorized documents.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Chroma, as a vector database, cosine similarity by default for searches.\n",
    "    db = Chroma.from_documents(data, embedding=embedding_function, \n",
    "                            #    collection_metadata={\"hnsw:space\": \"l2\"}\n",
    "                               collection_metadata={\"hnsw:space\": \"cosine\"}\n",
    "                               )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Embeddeing data to Vector Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_llm():\n",
    "    \"\"\"Initializes the LLM by reading the CSV file, loading the embeddings model, and vectorizing the documents.\n",
    "\n",
    "    Returns:\n",
    "        Chroma: A Chroma object that contains the vectorized documents.\n",
    "    \"\"\"\n",
    "    # Replace 'read_csv' with the appropriate CSV reading logic\n",
    "    data = read_csv(file_path='data/amazon_rag.csv', source_column=\"product_name\")\n",
    "    model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
    "    # model_name = 'jhgan/ko-sroberta-nli'\n",
    "    embedding_function = load_embeddings_model(model_name)\n",
    "    db = vectorize_documents(data, embedding_function)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43minit_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 12\u001b[0m, in \u001b[0;36minit_llm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# model_name = 'jhgan/ko-sroberta-nli'\u001b[39;00m\n\u001b[0;32m     11\u001b[0m embedding_function \u001b[38;5;241m=\u001b[39m load_embeddings_model(model_name)\n\u001b[1;32m---> 12\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mvectorize_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "Cell \u001b[1;32mIn[67], line 13\u001b[0m, in \u001b[0;36mvectorize_documents\u001b[1;34m(data, embedding_function)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Vectorizes a list of Documents using a Hugging Face Transformer model.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Chroma: A Chroma object that contains the vectorized documents.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m## Chroma, as a vector database, cosine similarity by default for searches.\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;66;43;03m#    collection_metadata={\"hnsw:space\": \"l2\"}\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhnsw:space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m db\n",
      "File \u001b[1;32mc:\\Users\\acj00\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:885\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[0;32m    867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \n\u001b[0;32m    869\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 885\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    886\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    888\u001b[0m         texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    889\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    898\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\acj00\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:885\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_documents\u001b[39m(\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[Chroma],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chroma:\n\u001b[0;32m    867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a Chroma vectorstore from a list of documents.\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \n\u001b[0;32m    869\u001b[0m \u001b[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;124;03m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 885\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_content\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    886\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(\n\u001b[0;32m    888\u001b[0m         texts\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m    889\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    898\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "db = init_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the vector database\n",
    "query = \"iPhone USB charger and adapter\"\n",
    "found_docs = db.similarity_search_with_score(query, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content='portronics konnect l 1.2m fast charging 3a 8 pin usb cable with charge & sync function for iphone, ipad (grey)'),\n",
       "  0.4407852292060852),\n",
       " (Document(metadata={}, page_content='swapkart fast charging cable and data sync usb cable compatible for iphone 6/6s/7/7+/8/8+/10/11, 12, 13 pro max ipad air/mini, ipod and ios devices (white)'),\n",
       "  0.46232080459594727),\n",
       " (Document(metadata={}, page_content='amazonbasics new release nylon usb-a to lightning cable cord, fast charging mfi certified charger for apple iphone, ipad (6-ft, rose gold)'),\n",
       "  0.47595155239105225),\n",
       " (Document(metadata={}, page_content='sounce fast phone charging cable & data sync usb cable compatible for iphone 13, 12,11, x, 8, 7, 6, 5, ipad air, pro, mini & ios devices'),\n",
       "  0.49668216705322266),\n",
       " (Document(metadata={}, page_content='amazonbasics nylon braided usb-c to lightning cable, fast charging mfi certified smartphone, iphone charger (6-foot, dark grey)'),\n",
       "  0.49811893701553345)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load documents\n",
    "found_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazonbasics nylon braided usb-c to lightning cable, fast charging mfi certified smartphone, iphone charger (6-foot, dark grey)\n",
      "\n",
      "Score: 0.49811893701553345\n"
     ]
    }
   ],
   "source": [
    "# Document with Score\n",
    "document, score = found_docs[-1]\n",
    "print(document.page_content)\n",
    "print(f\"\\nScore: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazonbasics nylon braided usb-c to lightning cable, fast charging mfi certified smartphone, iphone charger (6-foot, dark grey)'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_docs[-1][0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Get source \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfound_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'source'"
     ]
    }
   ],
   "source": [
    "#Get source \n",
    "found_docs[0][0].metadata['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_vector_search(query: str):\n",
    "#     # print(query)\n",
    "#     query_vector = db.similarity_search_with_score(query, k=5)\n",
    "#     # print(query_vector)\n",
    "#     # document, score = query_vector\n",
    "    \n",
    "#     # return query_vector.metadata['source'], document.page_content, score\n",
    "#     return query_vector\n",
    "\n",
    "def run_vector_search(query: str, k = 3) -> str:\n",
    "    \"\"\"Performs a vector search and returns results in a structured format.\"\"\"\n",
    "    query_vector = db.similarity_search_with_score(query, k=k)\n",
    "\n",
    "    # Extract and structure the search results\n",
    "    results = []\n",
    "    for document, score in query_vector:\n",
    "        # Extract metadata and page content\n",
    "        metadata = document.metadata\n",
    "        page_content = {k.strip(): v.strip() for k, v in [line.split(':', 1) for line in document.page_content.split('\\n') if ':' in line]}\n",
    "        \n",
    "        # Combine all data into a single dictionary\n",
    "        combined_result = {\n",
    "            \"source\": metadata.get(\"source\", \"Unknown Source\"),\n",
    "            **page_content,\n",
    "            \"score\": score\n",
    "        }\n",
    "        results.append(combined_result)\n",
    "\n",
    "    # Convert to a DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown Source</td>\n",
       "      <td>0.354823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown Source</td>\n",
       "      <td>0.355708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown Source</td>\n",
       "      <td>0.357370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source     score\n",
       "0  Unknown Source  0.354823\n",
       "1  Unknown Source  0.355708\n",
       "2  Unknown Source  0.357370"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_vector_search('what is the iphone cable?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text generation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "367f165eccea47629db2d60d074ba87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faf1abe46fb48818846b1a628358ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  53%|#####2    | 2.63G/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/42/7f/427f46441aabe23286fce919e9893cd9c666f839b80658e8a7a972bc1d646d83/db5ecebda6b1cd7203acc4e9a7eae9bdcf6edd21fdb59ad31b3fb622ed27c19c?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1733705384&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMzcwNTM4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQyLzdmLzQyN2Y0NjQ0MWFhYmUyMzI4NmZjZTkxOWU5ODkzY2Q5YzY2NmY4MzliODA2NThlOGE3YTk3MmJjMWQ2NDZkODMvZGI1ZWNlYmRhNmIxY2Q3MjAzYWNjNGU5YTdlYWU5YmRjZjZlZGQyMWZkYjU5YWQzMWIzZmI2MjJlZDI3YzE5Yz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=ga9ATrvD5CRvQKVMRumo3n40Qz4ATbLg6eFWsO5ZQbNAQaDvBcbKRsGuLT1zcSoVmIC43EO9DZoolQNlU2KYefRW1r6TYGhSPjE3dtYQTFuC4EFSbULlVilcZFme3GCsFaYZf5K4n6YseTiaE4rW%7EI8zNCWfkP1TPoeLcMWr-WWEFp%7EJqPGeddA61X6x%7EqmOBZdxt2YvG1EL95QN6gKm8EfnMCAg3BZuFQ-Pkx4K4KOMa8PWnhViwya8ab5hFulmx%7ESU4unXF1E4%7Eo%7ERPVF-U15XlCEX8i0KNI-W%7EwVSApfqnPNWkGuQOzl5BGM2LhgZsw8gEvZKpOYWXWCMJYb1%7EA__&Key-Pair-Id=K24J24Z295AEI9: [SSL] record layer failure (_ssl.c:2637)\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12a9015866644a2b83381d2ffcb2403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  81%|########1 | 4.06G/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e8697984bc4310a35dba5302ae13e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/logging/__init__.py\", line 1083, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/logging/__init__.py\", line 927, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/logging/__init__.py\", line 663, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/logging/__init__.py\", line 367, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3048, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3103, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3308, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3490, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/69/b5bztsf96dqc792smc_bsrg00000gn/T/ipykernel_57968/3737897784.py\", line 17, in <module>\n",
      "    pipeline = transformers.pipeline(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/pipelines/__init__.py\", line 940, in pipeline\n",
      "    framework, model = infer_framework_load_model(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/pipelines/base.py\", line 289, in infer_framework_load_model\n",
      "    model = model_class.from_pretrained(model, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 4130, in from_pretrained\n",
      "    model = cls(config, *model_args, **model_kwargs)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/models/gemma2/modeling_gemma2.py\", line 891, in __init__\n",
      "    super().__init__(config)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/modeling_utils.py\", line 1393, in __init__\n",
      "    self.generation_config = GenerationConfig.from_model_config(config) if self.can_generate() else None\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py\", line 1281, in from_model_config\n",
      "    generation_config = cls.from_dict(config_dict, return_unused_kwargs=False, _from_model_config=True)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py\", line 1137, in from_dict\n",
      "    config = cls(**{**config_dict, **kwargs})\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py\", line 509, in __init__\n",
      "    self.validate(is_init=True)\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/generation/configuration_utils.py\", line 789, in validate\n",
      "    logger.warning_once(\n",
      "  File \"/opt/anaconda3/envs/torch-env2/lib/python3.9/site-packages/transformers/utils/logging.py\", line 328, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.'\n",
      "Arguments: (<class 'UserWarning'>,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9604d0a91e41f194615c9feecea29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab9e5c72a064fd6ad812628cae24342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/213 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers \n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "# model = \"nilq/mistral-1L-tiny\" \n",
    "#huggingface-cli login\n",
    "#Reference: https://huggingface.co/docs/huggingface_hub/en/guides/cli\n",
    "\n",
    "model = \"ArliAI/Gemma-2-2B-ArliAI-RPMax-v1.1\"#'ArliAI/Mistral-Small-22B-ArliAI-RPMax-v1.1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model,  \n",
    "    use_auth_token= '', #본인의 Token 업데이트, \n",
    ")\n",
    "\n",
    "# pipeline \n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",  \n",
    "    model=model,    \n",
    "    torch_dtype=torch.float16,  \n",
    "    device_map=\"auto\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "promptTemplate_fstring = \"\"\"\n",
    "You are a customer service assistant, tasked with providing clear and concise answers based on the given context. \n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{query}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template='Question: {question}\\nAnswer:'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The 'batch_size' attribute of HybridCache is deprecated and will be removed in v4.49. Use the more precisely named 'self.max_batch_size' attribute instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "Answer: Electroencephalography is used to record the electrical activity of the brain through electrodes attached to the scalp.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt)\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a customer service assistant, tasked with providing clear and concise answers based on the given context. \n",
      "Context:\n",
      "                                                                                                                                               product_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     about_product\n",
      "swapkart fast charging cable and data sync usb cable compatible for iphone 6/6s/7/7+/8/8+/10/11, 12, 13 pro max ipad air/mini, ipod and ios devices (white) [High Compatibility] : This iphone data cable supports with iPhone 6,6s,6 plus,6s plus,7 7 plus ,8 8plus,x,xs,11 pro max,12 mini pro max,13 mini pro max iPad Air, iPad mini, iPod Nano and iPod Touch|[Fast Charge&Data Sync ] : It can charge and sync simultaneously at a rapid speed, Compatible with any charging adaptor, multi-port charging station or power bank ,for fast charging ,fast adapter is must.|😍【Durable Spring Protection】：The easy-to-break connection port is protected by spring, which is a flexible and durable cable.You can use it with confidence.|【 Ultra High Quality】: According to the experimental results, the fishbone design can accept at least 20,000 bending and insertion tests for extra protection and durability. Upgraded 3D aluminum connector and exclusive laser welding technology, which to ensure the metal part won't break and also have a tighter connection which fits well even with a protective case on and will never loose connection.|【 Good After Sales Service】-Our friendly and reliable customer service will respond to you within 24 hours ! you can purchase with confidence,and every sale includes a 365-day worry-free Service to prove the importance we set on quality.\n",
      "                            amazonbasics nylon braided usb-c to lightning cable, fast charging mfi certified smartphone, iphone charger (6-foot, dark grey)                                                                                                                                                                                                                                                                                                                                                         Fast Charge: When Used With An 18W Or Higher Usb-C Wall Charger With Power Delivery You Can Charge Your Iphone To 50% Battery In Just 30 Minutes - Supported Models Include Iphone 8, 8 Plus, X, Xs, Xr, Xs Max, 11, 11 Pro, 11 Pro Max, Ipads, And More. High-Speed Data Transfer: Up To 480 Mbps For Transferring Music, Movies, And More In Seconds|Durable Friendly Design: Built With Top Rated Materials And Tested To Withstand Up To X Bend Cycles And Features Textured Grooves On Connector Ends For Improved Grip|Certified Chip: Apple Mfi Certified Charging And Syncing Cable For Your Apple Devices With Improved Chipset To Ensure Full Compatibility|This Cable Is Not Compatible With Standard Usb Chargers / Laptop Ports. Works Only With Type C Adapters And Laptop Ports. Please Check The Port Of Your Adapter Before Buying The Cable.|Connector Type: Usb Type C\n",
      "                                   wayona nylon braided 3a lightning to usb a syncing and fast charging data cable for iphone, ipad (3 ft pack of 1, black)                                                                                                                                                                                                                                                                                                                                                                                                                                                         [High Compatibility] : iPhone X/XsMax/Xr ,iPhone 8/8 Plus,iPhone 7/7 Plus,iPhone 6s/6s Plus,iPhone 6/6 Plus,iPhone 5/5s/5c/se,iPad Pro,iPad Air 1/2,iPad mini 1/2/3,iPod nano7,iPod touch and more apple devices.|[Fast Charge&Data Sync ] : It can charge and sync simultaneously at a rapid speed, Compatible with any charging adaptor, multi-port charging station or power bank.|[Durability] : Durable nylon braided design with premium aluminum housing and toughened nylon fiber wound tightly around the cord lending it superior durability and adding a bit to its flexibility.|[High Security Level ] : It is designed to fully protect your device from damaging excessive current.Copper core thick+Multilayer shielding, Anti-interference, Protective circuit equipment.\n",
      "Question:\n",
      "suggest cool iPhone USB charger and adapter\n",
      "Answer:\n",
      "Swapkart fast charging cable and data sync USB cable compatible for iphone 6/6s/7\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Query definition\n",
    "query = \"suggest cool iPhone USB charger and adapter\"\n",
    "# query = \"what is the iphone cable?\"\n",
    "# query = \"What is the caracteristic of iPhone USB charger and adapter\"\n",
    "\n",
    "# Perform vector search\n",
    "doc_context = run_vector_search(query)\n",
    "\n",
    "# Extract relevant columns\n",
    "doc = doc_context[['product_name', 'about_product']]\n",
    "# doc = doc_context[[ 'about_product']]\n",
    "\n",
    "# print(doc)\n",
    "# Convert context to string\n",
    "context = doc.to_string(index=False)\n",
    "\n",
    "#You are an assistant in customer service. Use the following context to answer the question:\n",
    "\n",
    "# Define the prompt template\n",
    "# promptTemplate_fstring = \"\"\"\n",
    "# Context:\n",
    "# {context}\n",
    "# Question:\n",
    "# {query}\n",
    "# Answer:\n",
    "# \"\"\"\n",
    "\n",
    "promptTemplate_fstring = \"\"\"\n",
    "You are a customer service assistant, tasked with providing clear and concise answers based on the given context. \n",
    "Context:\n",
    "{context}\n",
    "Question:\n",
    "{query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the prompt\n",
    "prompt = PromptTemplate(\n",
    "    # input_variables=[\"query\", \"context\"],\n",
    "    template=promptTemplate_fstring,\n",
    ")\n",
    "\n",
    "# print(prompt)\n",
    "# Create the chain\n",
    "chain = LLMChain(prompt=prompt, llm=hf)\n",
    "\n",
    "# Run the chain and get the response\n",
    "response = chain.run({\"query\": query, \"context\": context})\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
